{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66659c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46a9b6d8",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c267816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "\n",
    "import astropy.units as u\n",
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sunpy.map\n",
    "import sunpy.visualization.colormaps.color_tables as ct\n",
    "from astropy.visualization import AsinhStretch, ImageNormalize\n",
    "from IPython.display import clear_output, display\n",
    "from matplotlib.patches import Rectangle\n",
    "from sunpy.coordinates import frames\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a8c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Library.Processing import *\n",
    "from Library.IO import *\n",
    "from Library.Model import *\n",
    "from Library.Metrics import *\n",
    "from Library.Config import *\n",
    "from Library.CH import *\n",
    "from Library.Plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944de574",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.width\", 10000)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326817b1",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(paths[\"artifact_root\"] + \"Paths.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[\"20170501\":\"20170801\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d5d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-wise subtraction\n",
    "inf_df = df.loc[~df.index.isin(train_df.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031066c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428dcd5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trained_model(\"A0\", \"D0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[4436]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = fits_to_pmap(model, prepare_fits(row.fits_path)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e0a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.min(), p.max(), p.mean(), p.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from Library.Config import paths\n",
    "from Library.Model import load_trained_model\n",
    "from Library import IO\n",
    "\n",
    "model = load_trained_model(\"A0\", \"D0\")\n",
    "df = pd.read_parquet(paths[\"artifact_root\"] + \"Paths.parquet\")\n",
    "val = df.iloc[-50:]  # or use your actual val split\n",
    "stats = []\n",
    "\n",
    "for row in val.itertuples():\n",
    "    _, img = IO.prepare_fits(row.fits_path)\n",
    "    x = IO.resize_for_model(img, model.architecture[\"img_size\"])[None, ..., None]\n",
    "    p = model.compiled_infer(x)[0, ..., 0]\n",
    "    stats.append([p.min(), p.max(), p.mean(), p.std()])\n",
    "\n",
    "print(np.mean(stats, axis=0))  # avg min/max/mean/std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2882020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Library.IO import prepare_mask\n",
    "for row in val.iloc[:5].itertuples():\n",
    "    _, img = IO.prepare_fits(row.fits_path)\n",
    "    x = IO.resize_for_model(img, model.architecture[\"img_size\"])[None, ..., None]\n",
    "    p = model.compiled_infer(x)[0, ..., 0]\n",
    "    m = IO.resize_for_model(prepare_mask(row.mask_path), model.architecture[\"img_size\"]) > 0\n",
    "    print(\"inside:\", p[m].mean(), \"outside:\", p[~m].mean(), \"std:\", p.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a0ce44",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12178d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Library import IO\n",
    "from Library.Model import load_pair\n",
    "from Library.Config import paths\n",
    "\n",
    "arch = json.load(open(\"Config/Model/Architecture/A0.json\"))\n",
    "df = pd.read_parquet(paths[\"artifact_root\"] + \"Paths.parquet\")\n",
    "row = df.iloc[0]\n",
    "\n",
    "train_img, train_mask = load_pair(row.fits_path, row.mask_path, arch)\n",
    "\n",
    "_, infer_img = IO.prepare_fits(row.fits_path)\n",
    "infer_img = IO.resize_for_model(infer_img.astype(np.float32), arch[\"img_size\"])\n",
    "infer_img = infer_img[..., None]\n",
    "\n",
    "def stats(x):\n",
    "    return {\n",
    "        \"min\": float(x.min()),\n",
    "        \"max\": float(x.max()),\n",
    "        \"mean\": float(x.mean()),\n",
    "        \"std\": float(x.std()),\n",
    "        \"p1\": float(np.percentile(x, 1)),\n",
    "        \"p99\": float(np.percentile(x, 99)),\n",
    "    }\n",
    "\n",
    "print(\"train:\", stats(train_img))\n",
    "print(\"infer:\", stats(infer_img))\n",
    "\n",
    "diff = train_img - infer_img\n",
    "print(\"diff:\", stats(diff), \"maxabs:\", float(np.abs(diff).max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "_, base_img = IO.prepare_fits(row.fits_path)\n",
    "x = base_img[np.newaxis, ..., np.newaxis].astype(np.float32)\n",
    "x = tf.image.resize(x, [arch[\"img_size\"], arch[\"img_size\"]], method=\"bilinear\").numpy()\n",
    "apply_img = x[0]\n",
    "w\n",
    "print(\"apply:\", stats(apply_img))\n",
    "diff2 = train_img - apply_img\n",
    "print(\"train-apply diff:\", stats(diff2), \"maxabs:\", float(np.abs(diff2).max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from Library.Config import paths\n",
    "from Library.IO import prepare_mask\n",
    "\n",
    "df = pd.read_parquet(paths[\"artifact_root\"] + \"Paths.parquet\")\n",
    "train_df = df[\"20170101\":\"20171231\"]  # adjust\n",
    "\n",
    "def has_pos(p):\n",
    "    m = prepare_mask(p)\n",
    "    return m.sum() > 0\n",
    "\n",
    "flags = train_df[\"mask_path\"].apply(has_pos)\n",
    "print(\"total:\", len(train_df), \"non-empty:\", flags.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45de2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = train_df[\"mask_path\"].sample(200).apply(\n",
    "    lambda p: prepare_mask(p).mean()\n",
    ")\n",
    "print(\"mean mask ratio:\", ratios.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Library import IO\n",
    "import numpy as np\n",
    "row = train_df.iloc[0]\n",
    "\n",
    "_, img = IO.prepare_fits(row.fits_path)\n",
    "mask = IO.prepare_mask(row.mask_path)\n",
    "\n",
    "m0 = img[mask > 0].mean()\n",
    "m1 = img[np.flipud(mask) > 0].mean()\n",
    "print(\"inside mean (mask):\", m0, \"inside mean (flipped mask):\", m1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b62494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Library.Config import paths\n",
    "from Library.Model import build_unet, bce_dice_loss, dice_coef, load_pair\n",
    "\n",
    "# Load a tiny slice\n",
    "df = pd.read_parquet(paths[\"artifact_root\"] + \"Paths.parquet\")\n",
    "tiny = df.iloc[4444:4446]  # pick 1–2 rows you know have CHs\n",
    "\n",
    "arch = json.load(open(\"Config/Model/Architecture/A0.json\"))\n",
    "arch[\"batch_size\"] = 4\n",
    "\n",
    "# Build training batch\n",
    "imgs, masks = [], []\n",
    "for row in tiny.itertuples():\n",
    "    img, mask = load_pair(row.fits_path, row.mask_path, arch)\n",
    "    imgs.append(img)\n",
    "    masks.append(mask)\n",
    "\n",
    "X = np.stack(imgs, axis=0).astype(np.float32)\n",
    "Y = np.stack(masks, axis=0).astype(np.float32)\n",
    "\n",
    "model = build_unet(arch)\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=bce_dice_loss,\n",
    "    metrics=[dice_coef, \"accuracy\"],\n",
    ")\n",
    "\n",
    "hist = model.fit(X, Y, epochs=50, verbose=1)\n",
    "pred = model.predict(X)\n",
    "\n",
    "print(\"pred stats\", pred.min(), pred.max(), pred.mean(), pred.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ae6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Y mean:\", Y.mean(), \"Y sum:\", Y.sum())   # make sure labels aren’t near‑zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet(arch)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"binary_crossentropy\"\n",
    ")\n",
    "model.fit(X, Y, epochs=50, batch_size=4, verbose=1)\n",
    "pred = model.predict(X)\n",
    "print(pred.min(), pred.max(), pred.mean(), pred.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = [w.numpy().copy() for w in model.trainable_weights]\n",
    "model.train_on_batch(X, Y)\n",
    "w1 = [w.numpy() for w in model.trainable_weights]\n",
    "max_delta = max(np.max(np.abs(a-b)) for a,b in zip(w0, w1))\n",
    "print(\"max weight delta:\", max_delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea443804",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss0 = model.evaluate(X, Y, verbose=0)\n",
    "for _ in range(20):\n",
    "    model.train_on_batch(X, Y)\n",
    "loss1 = model.evaluate(X, Y, verbose=0)\n",
    "print(\"loss0\", loss0, \"loss1\", loss1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icme3.10-metal",
   "language": "python",
   "name": "icme3.10-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
