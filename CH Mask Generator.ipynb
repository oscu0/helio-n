{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21218ecd",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from sunpy.map.maputils import all_coordinates_from_map, coordinate_is_on_solar_disk\n",
    "import sunpy.visualization.colormaps.color_tables as ct\n",
    "import sunpy.map\n",
    "import astropy.units as u\n",
    "from sunpy.coordinates import frames\n",
    "\n",
    "from skimage.morphology import (\n",
    "    binary_closing,\n",
    "    disk,\n",
    "    remove_small_objects,\n",
    "    remove_small_holes,\n",
    ")\n",
    "\n",
    "from skimage import measure\n",
    "import mahotas\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx\n",
    "# https://developer.apple.com/metal/jax/ (with keras via\n",
    "# multiscale sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "import keras\n",
    "\n",
    "# keras.config.set_backend(\"jax\")\n",
    "from keras import layers, ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "09edd2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_size': 256, 'batch_size': 4, 'num_epochs': 30, 'learning_rate': 0.0001}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./Config/Training Params.json\", \"r\") as f:\n",
    "    model_params = json.load(f)\n",
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0e43de02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'threshold': 0.32, 'closing_radius': 1, 'min_size': 150, 'hole_size': 1000.0}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./Config/Smoothing Params.json\", \"r\") as f:\n",
    "    smoothing_params = json.load(f)\n",
    "smoothing_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7af97",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FITS_ROOT = \"/Volumes/JetDrive 330/SDO Data/FITS\"\n",
    "MASKS_ROOT = \"/Volumes/JetDrive 330/SDO Data/Masks\"\n",
    "\n",
    "MODEL_PATH = \"./Outputs/model_CH_UNet.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_fits(f):\n",
    "    hpc_coords = all_coordinates_from_map(f)\n",
    "    mask = coordinate_is_on_solar_disk(hpc_coords)\n",
    "    palette = f.cmap.copy()\n",
    "    palette.set_bad(\"black\")\n",
    "    scaled_map = sunpy.map.Map(f.data, f.meta, mask=~mask)\n",
    "    ff = scaled_map.data\n",
    "    return ff\n",
    "\n",
    "\n",
    "def prepare_fits(path, mask_disk=True, clip_low=1, clip_high=99):\n",
    "    f = sunpy.map.Map(path)\n",
    "    if mask_disk:\n",
    "        ff = mask_fits(f).data\n",
    "    else:\n",
    "        ff = f.data\n",
    "    ff = np.flipud(ff)\n",
    "\n",
    "    low = np.percentile(ff, clip_low)\n",
    "    high = np.percentile(ff, clip_high)\n",
    "    ff = np.clip(ff, low, high)\n",
    "    ff = (ff - low) / (high - low + 1e-6)\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ef58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hmi_jpg(jpg_path, target_size=1024):\n",
    "    \"\"\"\n",
    "    Load 512px HMI JPEG (grayscale), upscale to target_size.\n",
    "    Return a float32 array.\n",
    "    \"\"\"\n",
    "    img = PIL.Image.open(jpg_path).convert(\"F\")  # 32-bit float\n",
    "    img = img.resize((target_size, target_size), resample=PIL.Image.BILINEAR)\n",
    "    arr = np.array(img, dtype=np.float32)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mask(path, preserve_255=False):\n",
    "    from PIL import Image\n",
    "\n",
    "    im = Image.open(path).convert(\"L\")\n",
    "    if not preserve_255:\n",
    "        arr = np.array(im, dtype=np.float32)\n",
    "        # Consider >127 as CH\n",
    "        arr = (arr > 127).astype(np.float32)\n",
    "    else:\n",
    "        arr = np.array(im)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hmi_jpg(\n",
    "    path=\"/Users/aosh/Library/Containers/net.langui.FTPMounter/Data/.FTPVolumes/dec1/mnt/sun/sdo/hmi/L0/2017/08/31/20170831_171500_M_512.jpg\",\n",
    "    target_size=(1024, 1024),\n",
    "):\n",
    "    \"\"\"\n",
    "    Load an HMI JPG (512×512 or similar) and upscale to AIA grid size.\n",
    "    Returns float32 magnetogram-like values in range [-1,1] based on brightness.\n",
    "    \"\"\"\n",
    "    im = Image.open(path).convert(\"L\")  # grayscale JPG\n",
    "    im = im.resize(target_size, Image.BILINEAR)\n",
    "    arr = np.array(im, dtype=np.float32)\n",
    "\n",
    "    # Convert brightness → rough polarity proxy:\n",
    "    # 0 = black → strong negative\n",
    "    # 255 = white → strong positive\n",
    "    # midpoint 128 → zero-ish\n",
    "    arr = (arr - 128.0) / 128.0  # now in approx [-1, +1]\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "\n",
    "def prepare_dataset(fits_root, masks_root):\n",
    "    def index(p):\n",
    "        return p.split(\"/\")[-1][3:16]\n",
    "\n",
    "    # Collect all FITS and masks\n",
    "    fits_files = glob.glob(os.path.join(fits_root, \"**\", \"*.fits\"), recursive=True)\n",
    "    mask_files = glob.glob(\n",
    "        os.path.join(masks_root, \"**\", \"*_CH_MASK_FINAL.png\"), recursive=True\n",
    "    )\n",
    "\n",
    "    df_fits = pd.DataFrame(\n",
    "        {\n",
    "            \"key\": [index(p) for p in fits_files],\n",
    "            \"fits_path\": fits_files,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_masks = pd.DataFrame(\n",
    "        {\n",
    "            \"key\": [index(p) for p in mask_files],\n",
    "            \"mask_path\": mask_files,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Optional: detect duplicate keys (same timestamp, multiple files)\n",
    "    dup_fits = df_fits[df_fits.duplicated(\"key\", keep=False)]\n",
    "    dup_masks = df_masks[df_masks.duplicated(\"key\", keep=False)]\n",
    "\n",
    "    if not dup_fits.empty:\n",
    "        print(\"⚠ Duplicate keys in FITS:\")\n",
    "        print(dup_fits.sort_values(\"key\"))\n",
    "\n",
    "    if not dup_masks.empty:\n",
    "        print(\"⚠ Duplicate keys in masks:\")\n",
    "        print(dup_masks.sort_values(\"key\"))\n",
    "\n",
    "    df_fits = df_fits.drop_duplicates(\"key\", keep=\"first\")\n",
    "    df_masks = df_masks.drop_duplicates(\"key\", keep=\"first\")\n",
    "\n",
    "    # Outer join to see everything in one table\n",
    "    merged = df_fits.merge(df_masks, on=\"key\", how=\"outer\", indicator=True)\n",
    "\n",
    "    matches = merged[merged[\"_merge\"] == \"both\"].copy()\n",
    "    fits_only = merged[merged[\"_merge\"] == \"left_only\"].copy()\n",
    "    masks_only = merged[merged[\"_merge\"] == \"right_only\"].copy()\n",
    "\n",
    "    for df in (matches, fits_only, masks_only):\n",
    "        df.drop(columns=[\"_merge\"], inplace=True)\n",
    "\n",
    "    matches.set_index(matches.key, inplace=True, drop=True)\n",
    "    matches.drop([\"key\"], axis=1, inplace=True)\n",
    "    matches[\"pmap_path\"] = \"\"\n",
    "\n",
    "    return matches, fits_only, masks_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_dataset(FITS_ROOT, MASKS_ROOT)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[\"20170501\":\"20170801\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-wise subtraction\n",
    "inf_df = df.loc[~df.index.isin(train_df.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9bf673",
   "metadata": {},
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02ff80",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb98bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_pair(img, mask):\n",
    "    # --- random horizontal flip ---\n",
    "    if np.random.rand() < 0.5:\n",
    "        img = img[:, ::-1, :]\n",
    "        mask = mask[:, ::-1, :]\n",
    "\n",
    "    # --- small random brightness scaling ---\n",
    "    scale = np.random.uniform(0.9, 1.1)  # ±10 %\n",
    "    img = img * scale\n",
    "    img = np.clip(img, 0.0, 1.0)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16896fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pair(fits_path, mask_path):\n",
    "    # decode paths if coming in as bytes\n",
    "    if isinstance(fits_path, (bytes, np.bytes_)):\n",
    "        fits_path = fits_path.decode(\"utf-8\")\n",
    "    if isinstance(mask_path, (bytes, np.bytes_)):\n",
    "        mask_path = mask_path.decode(\"utf-8\")\n",
    "\n",
    "    # load 2-D arrays\n",
    "    img = np.asarray(prepare_fits(fits_path), dtype=np.float32)\n",
    "    mask = np.asarray(prepare_mask(mask_path), dtype=np.float32)\n",
    "\n",
    "    # resize\n",
    "    img_resized = PIL.Image.fromarray((img * 255).astype(np.uint8)).resize(\n",
    "        (model_params[\"img_size\"], model_params[\"img_size\"]),\n",
    "        resample=PIL.Image.BILINEAR,\n",
    "    )\n",
    "    mask_resized = PIL.Image.fromarray((mask * 255).astype(np.uint8)).resize(\n",
    "        (model_params[\"img_size\"], model_params[\"img_size\"]), resample=PIL.Image.NEAREST\n",
    "    )\n",
    "\n",
    "    # normalize back to [0,1] and add channel axis\n",
    "    img = np.expand_dims(np.array(img_resized, dtype=np.float32) / 255.0, axis=-1)\n",
    "    mask = np.expand_dims(np.array(mask_resized, dtype=np.float32) / 255.0, axis=-1)\n",
    "    mask = (mask > 0.5).astype(np.float32)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ba2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_generator(fits_paths, mask_paths, augment=False):\n",
    "    n = len(fits_paths)\n",
    "    idxs = np.arange(n)\n",
    "\n",
    "    while True:\n",
    "        np.random.shuffle(idxs)\n",
    "        for i in range(0, n, model_params[\"batch_size\"]):\n",
    "            batch_idx = idxs[i : i + model_params[\"batch_size\"]]\n",
    "            imgs, masks = [], []\n",
    "            for j in batch_idx:\n",
    "                img, mask = load_pair(fits_paths[j], mask_paths[j])\n",
    "                if augment:\n",
    "                    img, mask = augment_pair(img, mask)\n",
    "\n",
    "                imgs.append(img)\n",
    "                masks.append(mask)\n",
    "\n",
    "            if not imgs:\n",
    "                continue\n",
    "\n",
    "            X = np.stack(imgs, axis=0).astype(np.float32)  # (B, H, W, 1)\n",
    "            Y = np.stack(masks, axis=0).astype(np.float32)  # (B, H, W, 1)\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb330829",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd340a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(x, filters):\n",
    "    x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(\n",
    "    input_shape=(model_params[\"img_size\"], model_params[\"img_size\"], 1), base_filters=32\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # ----- Encoder -----\n",
    "    c1 = double_conv(inputs, base_filters)  # 256 x 256,  f\n",
    "    p1 = layers.MaxPool2D(2)(c1)  # 128 x 128\n",
    "\n",
    "    c2 = double_conv(p1, base_filters * 2)  # 128 x 128,  2f\n",
    "    p2 = layers.MaxPool2D(2)(c2)  # 64 x 64\n",
    "\n",
    "    c3 = double_conv(p2, base_filters * 4)  # 64 x 64,    4f\n",
    "    p3 = layers.MaxPool2D(2)(c3)  # 32 x 32\n",
    "\n",
    "    c4 = double_conv(p3, base_filters * 8)  # 32 x 32,    8f\n",
    "    p4 = layers.MaxPool2D(2)(c4)  # 16 x 16\n",
    "\n",
    "    # extra encoder level\n",
    "    c5 = double_conv(p4, base_filters * 16)  # 16 x 16,   16f\n",
    "    p5 = layers.MaxPool2D(2)(c5)  # 8 x 8\n",
    "\n",
    "    # ----- Bottleneck -----\n",
    "    bn = double_conv(\n",
    "        p5, base_filters * 16\n",
    "    )  # keep 16f; base*32 is also possible but heavier\n",
    "\n",
    "    # ----- Decoder -----\n",
    "    u5 = layers.Conv2DTranspose(base_filters * 16, 2, strides=2, padding=\"same\")(bn)\n",
    "    u5 = layers.Concatenate()([u5, c5])\n",
    "    c6 = double_conv(u5, base_filters * 16)\n",
    "\n",
    "    u4 = layers.Conv2DTranspose(base_filters * 8, 2, strides=2, padding=\"same\")(c6)\n",
    "    u4 = layers.Concatenate()([u4, c4])\n",
    "    c7 = double_conv(u4, base_filters * 8)\n",
    "\n",
    "    u3 = layers.Conv2DTranspose(base_filters * 4, 2, strides=2, padding=\"same\")(c7)\n",
    "    u3 = layers.Concatenate()([u3, c3])\n",
    "    c8 = double_conv(u3, base_filters * 4)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(base_filters * 2, 2, strides=2, padding=\"same\")(c8)\n",
    "    u2 = layers.Concatenate()([u2, c2])\n",
    "    c9 = double_conv(u2, base_filters * 2)\n",
    "\n",
    "    u1 = layers.Conv2DTranspose(base_filters, 2, strides=2, padding=\"same\")(c9)\n",
    "    u1 = layers.Concatenate()([u1, c1])\n",
    "    c10 = double_conv(u1, base_filters)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(c10)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"CH_UNet_5lvl\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc17ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    # flatten per-sample\n",
    "    y_true_f = ops.reshape(y_true, (ops.shape(y_true)[0], -1))\n",
    "    y_pred_f = ops.reshape(y_pred, (ops.shape(y_pred)[0], -1))\n",
    "\n",
    "    intersection = ops.sum(y_true_f * y_pred_f, axis=1)\n",
    "    denom = ops.sum(y_true_f, axis=1) + ops.sum(y_pred_f, axis=1)\n",
    "\n",
    "    dice = (2.0 * intersection + smooth) / (denom + smooth)\n",
    "    return ops.mean(dice)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice_loss = 1.0 - dice_coef(y_true, y_pred)\n",
    "    return 0.4 * ops.mean(bce) + 0.6 * dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ee6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(pairs_df):\n",
    "    fits_paths = pairs_df[\"fits_path\"].astype(str).tolist()\n",
    "    mask_paths = pairs_df[\"mask_path\"].astype(str).tolist()\n",
    "\n",
    "    if len(fits_paths) == 0:\n",
    "        raise RuntimeError(\"pairs_df is empty: no FITS-mask pairs to train on.\")\n",
    "    if len(fits_paths) != len(mask_paths):\n",
    "        raise RuntimeError(\n",
    "            f\"Mismatch in pairs_df: {len(fits_paths)} FITS vs {len(mask_paths)} masks.\"\n",
    "        )\n",
    "\n",
    "    n_total = len(fits_paths)\n",
    "    print(f\"Training on {n_total} FITS-mask pairs\")\n",
    "\n",
    "    # 90/10 split\n",
    "    n_val = max(1, int(0.1 * n_total))\n",
    "    n_train = n_total - n_val\n",
    "\n",
    "    train_fits = fits_paths[:n_train]\n",
    "    train_masks = mask_paths[:n_train]\n",
    "    val_fits = fits_paths[n_train:]\n",
    "    val_masks = mask_paths[n_train:]\n",
    "\n",
    "    # --- use every 3rd training sample ---\n",
    "    train_fits = train_fits[::3]\n",
    "    train_masks = train_masks[::3]\n",
    "\n",
    "    # steps per epoch (integer)\n",
    "    steps_per_epoch = max(1, n_train // model_params[\"batch_size\"])\n",
    "    val_steps = max(1, n_val // model_params[\"batch_size\"])\n",
    "\n",
    "    train_gen = pair_generator(\n",
    "        train_fits,\n",
    "        train_masks,\n",
    "        augment=True,\n",
    "    )\n",
    "\n",
    "    val_gen = pair_generator(\n",
    "        val_fits,\n",
    "        val_masks,\n",
    "        augment=False,\n",
    "    )\n",
    "\n",
    "    model = build_unet(base_filters=80)  # must be built with keras.layers, not tf.keras\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=model_params[\"learning_rate\"]),\n",
    "        loss=bce_dice_loss,  # your keras.ops-based loss\n",
    "        metrics=[dice_coef, \"accuracy\"],\n",
    "    )\n",
    "\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            MODEL_PATH,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "        ),\n",
    "        early_stop,\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        epochs=model_params[\"num_epochs\"],\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=val_steps,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    print(f\"Training finished. Best model saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2056220f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7619f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model():\n",
    "    custom_objects = {\n",
    "        \"bce_dice_loss\": bce_dice_loss,\n",
    "        \"dice_coef\": dice_coef,\n",
    "    }\n",
    "    model = keras.models.load_model(MODEL_PATH, custom_objects=custom_objects)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e922ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trained_model()\n",
    "!notify \"Model loaded\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37dd9fc",
   "metadata": {},
   "source": [
    "# Model Application Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fits_to_pmap(img2d, resize=False, img_size=model_params[\"img_size\"]):\n",
    "    img = np.asarray(img2d, dtype=np.float32)\n",
    "\n",
    "    if img.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D array, got shape {img.shape}\")\n",
    "\n",
    "    if resize and img.shape != (img_size, img_size):\n",
    "        # Use float-preserving PIL mode \"F\", bilinear interpolation\n",
    "        pil_img = PIL.Image.fromarray(img.astype(np.float32), mode=\"F\")\n",
    "        pil_img = pil_img.resize((img_size, img_size), resample=PIL.Image.BILINEAR)\n",
    "        img = np.array(pil_img, dtype=np.float32)\n",
    "\n",
    "    x = img[np.newaxis, ..., np.newaxis]  # (1, H, W, 1)\n",
    "\n",
    "    prob = model.predict(x, verbose=0)[0, ..., 0]\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmap_to_mask(pmap, smoothing_params=smoothing_params, save=False):\n",
    "    mask = pmap > smoothing_params[\"threshold\"]  # binary mask\n",
    "\n",
    "    if smoothing_params[\"closing_radius\"] > 0:\n",
    "        mask = binary_closing(mask, disk(smoothing_params[\"closing_radius\"]))\n",
    "\n",
    "    if smoothing_params[\"min_size\"] > 0:\n",
    "        mask = remove_small_objects(mask, min_size=smoothing_params[\"min_size\"])\n",
    "\n",
    "    if smoothing_params[\"hole_size\"] > 0:\n",
    "        mask = remove_small_holes(mask, area_threshold=smoothing_params[\"hole_size\"])\n",
    "\n",
    "    # mask_uint8 = (mask * 255).clip(0, 255).astype(np.uint8)\n",
    "    img = PIL.Image.fromarray(mask)\n",
    "\n",
    "    if img.size != (1024, 1024):\n",
    "        img = img.resize((1024, 1024), resample=PIL.Image.NEAREST)\n",
    "\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pmap(row, pmap=None):\n",
    "    path = row.mask_path.replace(\"CH_MASK_FINAL.png\", \"UNET_PMAP.npy\")\n",
    "    if pmap is None:\n",
    "        pmap = fits_to_pmap(prepare_fits(row.fits_path))\n",
    "    np.save(path, pmap)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c42f1d5",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88073186",
   "metadata": {},
   "source": [
    "## Similarity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e97d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_binary_mask(mask):\n",
    "    \"\"\"Convert mask to boolean 2D array.\"\"\"\n",
    "    mask = np.asarray(mask)\n",
    "    if mask.ndim != 2:\n",
    "        raise ValueError(f\"mask must be 2D, got shape {mask.shape}\")\n",
    "    if mask.dtype == bool:\n",
    "        return mask\n",
    "    return mask > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dede75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zernike_descriptor(mask, degree=8):\n",
    "    \"\"\"\n",
    "    Compute Zernike-moment-based shape descriptor for a binary mask,\n",
    "    using mahotas.features.zernike_moments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : 2D array-like (bool or 0/1)\n",
    "        Binary mask of a single region (or union of CHs).\n",
    "    degree : int\n",
    "        Maximum Zernike polynomial degree (typical: 6–12).\n",
    "        This 'degree' in mahotas is 'n_max' in the literature.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    desc : np.ndarray, shape (M,)\n",
    "        Rotation-invariant Zernike descriptor (magnitudes), L2-normalized.\n",
    "        If the mask is empty, returns a zero vector of length 1.\n",
    "    \"\"\"\n",
    "    mask = _ensure_binary_mask(mask)\n",
    "\n",
    "    # --- crop to bounding box of the region ---\n",
    "    ys, xs = np.nonzero(mask)\n",
    "    if len(xs) == 0:\n",
    "        # empty mask\n",
    "        return np.zeros(1, dtype=float)\n",
    "\n",
    "    y_min, y_max = ys.min(), ys.max()\n",
    "    x_min, x_max = xs.min(), xs.max()\n",
    "    cropped = mask[y_min : y_max + 1, x_min : x_max + 1]\n",
    "\n",
    "    h, w = cropped.shape\n",
    "    # make it square by padding (centered)\n",
    "    size = max(h, w)\n",
    "    pad_y = (size - h) // 2\n",
    "    pad_x = (size - w) // 2\n",
    "\n",
    "    square = np.zeros((size, size), dtype=float)\n",
    "    square[pad_y : pad_y + h, pad_x : pad_x + w] = cropped.astype(float)\n",
    "\n",
    "    # mahotas assumes the Zernike circle is centered in the image\n",
    "    radius = size // 2\n",
    "\n",
    "    # mahotas.features.zernike_moments returns a 1D array of (real) magnitudes,\n",
    "    # already rotation-invariant\n",
    "    zm = mahotas.features.zernike_moments(square, radius, degree)\n",
    "\n",
    "    desc = np.asarray(zm, dtype=float)\n",
    "\n",
    "    # Optional: L2 normalize to make scale of descriptor comparable across regions\n",
    "    norm = np.linalg.norm(desc)\n",
    "    if norm > 0:\n",
    "        desc = desc / norm\n",
    "\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fourier_descriptor(mask, num_descriptors=20, n_samples=256):\n",
    "    \"\"\"\n",
    "    Compute Fourier shape descriptor from the boundary of a binary mask.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : 2D array-like (bool or 0/1)\n",
    "        Binary mask of a region (or union of CHs).\n",
    "    num_descriptors : int\n",
    "        Number of low-frequency coefficients to keep (excluding DC).\n",
    "    n_samples : int\n",
    "        Number of boundary points to resample to (uniform along contour).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    desc : np.ndarray, shape (num_descriptors,)\n",
    "        Rotation/translation/starting-point invariant boundary descriptor,\n",
    "        based on magnitudes of low-frequency Fourier coefficients.\n",
    "    \"\"\"\n",
    "    mask = _ensure_binary_mask(mask)\n",
    "\n",
    "    # --- find contours at 0.5 ---\n",
    "    contours = measure.find_contours(mask.astype(float), level=0.5)\n",
    "    if len(contours) == 0:\n",
    "        # empty mask\n",
    "        return np.zeros(num_descriptors, dtype=float)\n",
    "\n",
    "    # choose the longest contour (largest region)\n",
    "    contour = max(contours, key=lambda c: c.shape[0])\n",
    "\n",
    "    # contour: array of shape (N, 2) with (row, col) = (y, x)\n",
    "    ys, xs = contour[:, 0], contour[:, 1]\n",
    "\n",
    "    # --- resample to fixed number of points along the contour length ---\n",
    "    # compute cumulative distance along contour\n",
    "    dy = np.diff(ys)\n",
    "    dx = np.diff(xs)\n",
    "    dists = np.sqrt(dx**2 + dy**2)\n",
    "    cumlen = np.concatenate([[0], np.cumsum(dists)])\n",
    "    total_len = cumlen[-1]\n",
    "\n",
    "    if total_len == 0:\n",
    "        return np.zeros(num_descriptors, dtype=float)\n",
    "\n",
    "    # new parameterization from 0 to total_len\n",
    "    target = np.linspace(0, total_len, n_samples, endpoint=False)\n",
    "    # interpolate x(t), y(t)\n",
    "    xs_resampled = np.interp(target, cumlen, xs)\n",
    "    ys_resampled = np.interp(target, cumlen, ys)\n",
    "\n",
    "    # --- build complex sequence and normalize ---\n",
    "    z = xs_resampled + 1j * ys_resampled\n",
    "\n",
    "    # translation invariance: subtract centroid\n",
    "    z = z - z.mean()\n",
    "\n",
    "    # scale invariance: normalize by RMS radius\n",
    "    scale = np.sqrt(np.mean(np.abs(z) ** 2))\n",
    "    if scale > 0:\n",
    "        z = z / scale\n",
    "\n",
    "    # --- Fourier transform along contour index ---\n",
    "    Z = np.fft.fft(z)\n",
    "    # We ignore the DC term Z[0] (translation)\n",
    "    # and use the first num_descriptors low-frequency terms.\n",
    "    # For invariance to starting point & rotation, use magnitudes.\n",
    "    # freq indices: 1..num_descriptors\n",
    "    max_k = min(num_descriptors, len(Z) // 2)\n",
    "    coeffs = Z[1 : max_k + 1]\n",
    "    desc = np.abs(coeffs)\n",
    "\n",
    "    # zero-pad if needed\n",
    "    if len(desc) < num_descriptors:\n",
    "        pad = np.zeros(num_descriptors - len(desc), dtype=float)\n",
    "        desc = np.concatenate([desc, pad])\n",
    "\n",
    "    # optional second normalization\n",
    "    norm = np.linalg.norm(desc)\n",
    "    if norm > 0:\n",
    "        desc = desc / norm\n",
    "\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07279d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Compute Intersection-over-Union (IoU) for two binary masks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask1, mask2 : array-like\n",
    "        2D numpy arrays. Values can be {0,1}, {0,255}, float, or bool.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        IoU value in [0,1].\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to boolean\n",
    "    m1 = np.asarray(mask1) > 0.5\n",
    "    m2 = np.asarray(mask2) > 0.5\n",
    "\n",
    "    intersection = np.logical_and(m1, m2).sum()\n",
    "    union = np.logical_or(m1, m2).sum()\n",
    "\n",
    "    if union == 0:\n",
    "        return 1.0 if intersection == 0 else 0.0\n",
    "\n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ece95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(mask1, mask2):\n",
    "    m1 = np.asarray(mask1) > 0.5\n",
    "    m2 = np.asarray(mask2) > 0.5\n",
    "\n",
    "    intersection = np.logical_and(m1, m2).sum()\n",
    "    a1 = m1.sum()\n",
    "    a2 = m2.sum()\n",
    "\n",
    "    denom = a1 + a2\n",
    "    if denom == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return 2.0 * intersection / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_distance(desc_a, desc_b, metric=\"l2\"):\n",
    "    \"\"\"\n",
    "    Compute distance between two descriptor vectors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    desc_a, desc_b : array-like\n",
    "        Descriptor vectors (e.g., Zernike or Fourier descriptors).\n",
    "    metric : {\"l2\", \"l1\", \"cosine\"}\n",
    "        Distance / dissimilarity measure.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    d : float\n",
    "        Distance (larger = more dissimilar).\n",
    "    \"\"\"\n",
    "    a = np.asarray(desc_a, dtype=float)\n",
    "    b = np.asarray(desc_b, dtype=float)\n",
    "\n",
    "    if metric == \"l2\":\n",
    "        return np.linalg.norm(a - b)\n",
    "    elif metric == \"l1\":\n",
    "        return np.sum(np.abs(a - b))\n",
    "    elif metric == \"cosine\":\n",
    "        na = np.linalg.norm(a)\n",
    "        nb = np.linalg.norm(b)\n",
    "        if na == 0 or nb == 0:\n",
    "            return 1.0  # maximal dissimilarity\n",
    "        cos_sim = np.dot(a, b) / (na * nb)\n",
    "        return 1.0 - cos_sim  # cosine distance\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown metric: {metric!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a788a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_x = [384, 640]\n",
    "range_y = [256, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_area(mask):\n",
    "    return mask[range_y[0] : range_y[1], range_x[0] : range_x[1]].flatten().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c039f54",
   "metadata": {},
   "source": [
    "## Coronal Hole Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_SUN = 6.957e8 * u.m  # solar radius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1628c9",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5697c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(row, smoothing_params=smoothing_params, m2=None):\n",
    "    m1 = prepare_mask(row.mask_path)\n",
    "    if m2 is None:\n",
    "        m2 = pmap_to_mask(fits_to_pmap(prepare_fits(row.fits_path)), smoothing_params)\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    stats[\"fourier_distance\"] = shape_distance(\n",
    "        compute_fourier_descriptor(m1),\n",
    "        compute_fourier_descriptor(m2),\n",
    "    )\n",
    "\n",
    "    stats[\"zernike_distance\"] = shape_distance(\n",
    "        compute_zernike_descriptor(m1),\n",
    "        compute_zernike_descriptor(m2),\n",
    "    )\n",
    "\n",
    "    stats[\"rel_area\"] = 1 - (rect_area(m2) / rect_area(m1))\n",
    "\n",
    "    stats[\"iou\"] = iou(m1, m2)\n",
    "    stats[\"dice\"] = dice(m1, m2)\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e033410",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = ct.aia_color_table(u.Quantity(193, \"Angstrom\"))\n",
    "# cmap = \"gray\"\n",
    "\n",
    "\n",
    "def print_distance(row, smoothing_params=smoothing_params):\n",
    "    s = stats(row, smoothing_params)\n",
    "\n",
    "    print(\"Fourier Distance: \", s[\"fourier_distance\"])\n",
    "    print(\"Zernike Distance: \", s[\"zernike_distance\"])\n",
    "    print(\"Center CH Area Difference (non-projective): \", s[\"rel_area\"])\n",
    "    print(\"I over U: \", s[\"iou\"])\n",
    "    print(\"Dice: \", s[\"dice\"])\n",
    "\n",
    "\n",
    "def plot_mask(row, smoothing_params=smoothing_params):\n",
    "    print(row)\n",
    "    print_distance(row, smoothing_params)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(\n",
    "        pmap_to_mask(fits_to_pmap(prepare_fits(row.fits_path)), smoothing_params),\n",
    "        cmap=cmap,\n",
    "    )\n",
    "    plt.gca().add_patch(\n",
    "        Rectangle(\n",
    "            [range_x[0], range_y[0]],\n",
    "            range_x[1] - range_x[0],\n",
    "            range_y[1] - range_y[0],\n",
    "            linewidth=1,\n",
    "            edgecolor=\"y\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "    )\n",
    "    plt.title(\"helio-n (U-Net)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.array(PIL.Image.open(row.mask_path)), cmap=cmap)\n",
    "    plt.gca().add_patch(\n",
    "        Rectangle(\n",
    "            [range_x[0], range_y[0]],\n",
    "            range_x[1] - range_x[0],\n",
    "            range_y[1] - range_y[0],\n",
    "            linewidth=1,\n",
    "            edgecolor=\"y\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "    )\n",
    "    plt.title(\"IDL\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sdo(row, smoothing_params):\n",
    "    print(row)\n",
    "    print_distance(row, smoothing_params)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(prepare_fits(row.fits_path), cmap=cmap)\n",
    "    plt.contour(\n",
    "        pmap_to_mask(fits_to_pmap(prepare_fits(row.fits_path)), smoothing_params),\n",
    "        levels=[0.5],\n",
    "        colors=\"red\",\n",
    "        linewidths=1.5,\n",
    "    )\n",
    "    plt.gca().add_patch(\n",
    "        Rectangle(\n",
    "            (range_x[0], range_y[0]),\n",
    "            range_x[1] - range_x[0],\n",
    "            range_y[1] - range_y[0],\n",
    "            linewidth=1,\n",
    "            edgecolor=\"y\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    plt.title(\"helio-n (U-Net)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(prepare_fits(row.fits_path), cmap=cmap)\n",
    "    plt.contour(\n",
    "        np.array(prepare_mask(row.mask_path)),\n",
    "        levels=[0.5],\n",
    "        colors=\"red\",\n",
    "        linewidths=1.5,\n",
    "    )\n",
    "    plt.gca().add_patch(\n",
    "        Rectangle(\n",
    "            (range_x[0], range_y[0]),\n",
    "            range_x[1] - range_x[0],\n",
    "            range_y[1] - range_y[0],\n",
    "            linewidth=1,\n",
    "            edgecolor=\"y\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    plt.title(\"IDL\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a5c2f",
   "metadata": {},
   "source": [
    "## UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2650f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Register your dataframes here\n",
    "dfs = {\n",
    "    \"train\": train_df,\n",
    "    \"inference\": inf_df,\n",
    "}\n",
    "\n",
    "# 2. Widgets\n",
    "df_selector = widgets.RadioButtons(\n",
    "    options=list(dfs.keys()),\n",
    "    value=\"inference\",\n",
    "    description=\"DataFrame:\",\n",
    ")\n",
    "\n",
    "idx_slider = widgets.IntSlider(\n",
    "    value=random.randint(0, len(dfs[\"train\"]) - 1),\n",
    "    min=0,\n",
    "    max=len(dfs[\"train\"]) - 1,\n",
    "    step=1,\n",
    "    description=\"Index:\",\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "show_mask_checkbox = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Show Mask Only\",\n",
    ")\n",
    "\n",
    "# New sliders\n",
    "threshold_slider = widgets.FloatSlider(\n",
    "    value=smoothing_params[\"threshold\"],\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    description=\"Threshold\",\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "closing_radius_slider = widgets.IntSlider(\n",
    "    value=smoothing_params[\"closing_radius\"],\n",
    "    min=0,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description=\"Closing R\",\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "min_size_slider = widgets.IntSlider(\n",
    "    value=smoothing_params[\"min_size\"],\n",
    "    min=0,\n",
    "    max=2000,\n",
    "    step=10,\n",
    "    description=\"Min size\",\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "hole_size_slider = widgets.FloatSlider(\n",
    "    value=smoothing_params[\"hole_size\"],\n",
    "    min=0.0,\n",
    "    max=5000,\n",
    "    step=50,\n",
    "    description=\"Hole area\",\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "# 3. Update slider range when DF changes\n",
    "def update_slider_range(change):\n",
    "    df = dfs[df_selector.value]\n",
    "    idx_slider.max = max(0, len(df) - 1)\n",
    "    if idx_slider.value > idx_slider.max:\n",
    "        idx_slider.value = idx_slider.max\n",
    "\n",
    "\n",
    "df_selector.observe(update_slider_range, names=\"value\")\n",
    "\n",
    "\n",
    "# 4. Main update function\n",
    "def update_plot(change=None):\n",
    "    global smoothing_params\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        df = dfs[df_selector.value]\n",
    "        if len(df) == 0:\n",
    "            print(\"Selected dataframe is empty.\")\n",
    "            return\n",
    "\n",
    "        row = df.iloc[idx_slider.value]\n",
    "\n",
    "        thr = threshold_slider.value\n",
    "        cr = closing_radius_slider.value\n",
    "        ms = min_size_slider.value\n",
    "        ha = hole_size_slider.value\n",
    "\n",
    "        smoothing_params = {\n",
    "            \"threshold\": thr,\n",
    "            \"closing_radius\": cr,\n",
    "            \"min_size\": ms,\n",
    "            \"hole_size\": ha,\n",
    "        }\n",
    "\n",
    "        if show_mask_checkbox.value:\n",
    "            # Should plot SDO + NN/IDL mask\n",
    "            plot_mask(\n",
    "                row,\n",
    "                {\n",
    "                    \"threshold\": thr,\n",
    "                    \"closing_radius\": cr,\n",
    "                    \"min_size\": ms,\n",
    "                    \"hole_size\": ha,\n",
    "                },\n",
    "            )\n",
    "        else:\n",
    "            # Should plot just the SDO / FITS-based view\n",
    "            plot_sdo(\n",
    "                row,\n",
    "                {\n",
    "                    \"threshold\": thr,\n",
    "                    \"closing_radius\": cr,\n",
    "                    \"min_size\": ms,\n",
    "                    \"hole_size\": ha,\n",
    "                },\n",
    "            )\n",
    "\n",
    "    with open(\"./Config/smoothing_params.json\", \"w\") as f:\n",
    "        json.dump(smoothing_params, f)\n",
    "\n",
    "\n",
    "# 5. Hook up callbacks\n",
    "idx_slider.observe(update_plot, names=\"value\")\n",
    "show_mask_checkbox.observe(update_plot, names=\"value\")\n",
    "df_selector.observe(update_plot, names=\"value\")\n",
    "threshold_slider.observe(update_plot, names=\"value\")\n",
    "closing_radius_slider.observe(update_plot, names=\"value\")\n",
    "min_size_slider.observe(update_plot, names=\"value\")\n",
    "hole_size_slider.observe(update_plot, names=\"value\")\n",
    "\n",
    "# 6. Display the UI\n",
    "controls_top = widgets.HBox(\n",
    "    [\n",
    "        df_selector,\n",
    "        idx_slider,\n",
    "        show_mask_checkbox,\n",
    "    ]\n",
    ")\n",
    "\n",
    "controls_bottom = widgets.HBox(\n",
    "    [\n",
    "        threshold_slider,\n",
    "        closing_radius_slider,\n",
    "        min_size_slider,\n",
    "        hole_size_slider,\n",
    "    ]\n",
    ")\n",
    "\n",
    "ui = widgets.VBox(\n",
    "    [\n",
    "        controls_top,\n",
    "        controls_bottom,\n",
    "        out,\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(ui)\n",
    "\n",
    "# Initial draw\n",
    "update_slider_range(None)\n",
    "update_plot(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e0f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Outputs/smoothing_params.json\", \"w\") as f:\n",
    "    json.dump(smoothing_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b05c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e06eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "key",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fits_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mask_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pmap_path",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8dd8adc9-d49f-422d-8d59-b623dbe5a28e",
       "rows": [
        [
         "20160101_0000",
         "/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01/AIA20160101_000000_0193.fits",
         "/Volumes/JetDrive 330/SDO Data/Masks/2016/01/AIA20160101_000005_0193_CH_MASK_FINAL.png",
         ""
        ],
        [
         "20160101_0002",
         "/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01/AIA20160101_000200_0193.fits",
         "/Volumes/JetDrive 330/SDO Data/Masks/2016/01/AIA20160101_000205_0193_CH_MASK_FINAL.png",
         ""
        ],
        [
         "20160101_0046",
         "/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01/AIA20160101_0046_0193.fits",
         "/Volumes/JetDrive 330/SDO Data/Masks/2016/01/AIA20160101_004605_0193_CH_MASK_FINAL.png",
         ""
        ],
        [
         "20160101_0100",
         "/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01/AIA20160101_010000_0193.fits",
         "/Volumes/JetDrive 330/SDO Data/Masks/2016/01/AIA20160101_010005_0193_CH_MASK_FINAL.png",
         ""
        ],
        [
         "20160101_0102",
         "/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01/AIA20160101_010200_0193.fits",
         "/Volumes/JetDrive 330/SDO Data/Masks/2016/01/AIA20160101_010205_0193_CH_MASK_FINAL.png",
         ""
        ],
        [
         "20160101_0154",
         "/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01/AIA20160101_0154_0193.fits",
         "/Volumes/JetDrive 330/SDO Data/Masks/2016/01/AIA20160101_015405_0193_CH_MASK_FINAL.png",
         ""
        ],
        [
         "20160101_0200",
         "/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01/AIA20160101_020000_0193.fits",
         "/Volumes/JetDrive 330/SDO Data/Masks/2016/01/AIA20160101_020005_0193_CH_MASK_FINAL.png",
         ""
        ],
        [
         "20160101_0202",
         "/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01/AIA20160101_020200_0193.fits",
         "/Volumes/JetDrive 330/SDO Data/Masks/2016/01/AIA20160101_020205_0193_CH_MASK_FINAL.png",
         ""
        ],
        [
         "20160101_0246",
         "/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01/AIA20160101_0246_0193.fits",
         "/Volumes/JetDrive 330/SDO Data/Masks/2016/01/AIA20160101_024605_0193_CH_MASK_FINAL.png",
         ""
        ],
        [
         "20160101_0300",
         "/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01/AIA20160101_030000_0193.fits",
         "/Volumes/JetDrive 330/SDO Data/Masks/2016/01/AIA20160101_030005_0193_CH_MASK_FINAL.png",
         ""
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fits_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>pmap_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20160101_0000</th>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...</td>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160101_0002</th>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...</td>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160101_0046</th>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...</td>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160101_0100</th>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...</td>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160101_0102</th>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...</td>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160101_0154</th>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...</td>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160101_0200</th>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...</td>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160101_0202</th>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...</td>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160101_0246</th>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...</td>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160101_0300</th>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...</td>\n",
       "      <td>/Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       fits_path                                          mask_path pmap_path\n",
       "key                                                                                                                          \n",
       "20160101_0000  /Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...  /Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...          \n",
       "20160101_0002  /Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...  /Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...          \n",
       "20160101_0046  /Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...  /Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...          \n",
       "20160101_0100  /Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...  /Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...          \n",
       "20160101_0102  /Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...  /Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...          \n",
       "20160101_0154  /Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...  /Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...          \n",
       "20160101_0200  /Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...  /Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...          \n",
       "20160101_0202  /Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...  /Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...          \n",
       "20160101_0246  /Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...  /Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...          \n",
       "20160101_0300  /Volumes/JetDrive 330/SDO Data/FITS/2016/01/01...  /Volumes/JetDrive 330/SDO Data/Masks/2016/01/A...          "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ed3dac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/b4fclst96kbd90mb019v618m0000gn/T/ipykernel_6723/2963093334.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ddf.mask_path = ddf.apply(save_pmap, axis=1)\n"
     ]
    }
   ],
   "source": [
    "ddf.mask_path = ddf.apply(save_pmap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761dc937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inf_df[\"nn_map\"] = inf_df.apply(lambda x: mask_via_pmap(prepare_fits(x.fits_path)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inf_df[\"stats\"] = inf_df.apply(lambda x: stats(x, m2=x.nn_map), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42015109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_polarity(row, smoothing_params, B_thresh=0.15):\n",
    "    \"\"\"\n",
    "    row: DataFrame row with row.fits_path and row.mask_path and row.hmi_path (JPG)\n",
    "    smoothing_params: mask-via-model parameters\n",
    "    \"\"\"\n",
    "\n",
    "    aia = prepare_fits(row.fits_path)  # (1024×1024, normalized)\n",
    "    hmi = prepare_hmi_jpg()  # upscale JPG → match AIA grid\n",
    "\n",
    "    nn_mask_raw = mask_via_pmap(row, smoothing_params)\n",
    "    nn_mask = nn_mask_raw > 0.5\n",
    "\n",
    "    idl_mask_raw = prepare_mask(row.mask_path)\n",
    "    idl_mask = idl_mask_raw > 0.5\n",
    "\n",
    "    # polarity masks using pseudo-HMI field\n",
    "    nn_pos = nn_mask & (hmi >= B_thresh)\n",
    "    nn_neg = nn_mask & (hmi <= -B_thresh)\n",
    "\n",
    "    idl_pos = idl_mask & (hmi >= B_thresh)\n",
    "    idl_neg = idl_mask & (hmi <= -B_thresh)\n",
    "\n",
    "    # build RGBA overlays\n",
    "    def make_overlay(pos, neg, alpha=0.5):\n",
    "        h, w = pos.shape\n",
    "        rgba_pos = np.zeros((h, w, 4), dtype=np.float32)\n",
    "        rgba_neg = np.zeros((h, w, 4), dtype=np.float32)\n",
    "\n",
    "        rgba_pos[..., 0] = 1.0  # red\n",
    "        rgba_pos[..., 3] = alpha * pos.astype(float)\n",
    "\n",
    "        rgba_neg[..., 2] = 1.0  # blue\n",
    "        rgba_neg[..., 3] = alpha * neg.astype(float)\n",
    "\n",
    "        return rgba_pos, rgba_neg\n",
    "\n",
    "    nn_overlay_pos, nn_overlay_neg = make_overlay(nn_pos, nn_neg)\n",
    "    idl_overlay_pos, idl_overlay_neg = make_overlay(idl_pos, idl_neg)\n",
    "\n",
    "    # plots\n",
    "    print_distance(row, smoothing_params)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # ------------------ U-Net ------------------\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(aia, cmap=cmap)\n",
    "    plt.contour(nn_mask.astype(float), levels=[0.5], colors=\"red\")\n",
    "    plt.imshow(nn_overlay_pos)\n",
    "    plt.imshow(nn_overlay_neg)\n",
    "    plt.title(\"helio-n: red=+, blue=-\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # ------------------ IDL ------------------\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(aia, cmap=cmap)\n",
    "    plt.contour(idl_mask.astype(float), levels=[0.5], colors=\"red\")\n",
    "    plt.imshow(idl_overlay_pos)\n",
    "    plt.imshow(idl_overlay_neg)\n",
    "    plt.title(\"IDL: red=+, blue=-\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba21629",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_polarity(inf_df.iloc[13385], smoothing_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568b148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icme3.10 (TF, Metal)",
   "language": "python",
   "name": "icme3.10-nn-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
