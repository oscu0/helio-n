{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd2b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sunpy.map.maputils import all_coordinates_from_map, coordinate_is_on_solar_disk\n",
    "import sunpy.visualization.colormaps.color_tables as ct\n",
    "import sunpy.map\n",
    "\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32a38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx\n",
    "# https://developer.apple.com/metal/jax/ (with keras via\n",
    "# multiscale sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75b8075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "import keras\n",
    "# keras.config.set_backend(\"jax\")\n",
    "from keras import layers, ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f70e8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7af97",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e065bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FITS_ROOT = \"./Data/Training/FITS\"\n",
    "TRAIN_MASKS_ROOT = \"./Data/Training/Masks\"\n",
    "\n",
    "MODEL_PATH = \"model_CH_UNet.keras\"\n",
    "\n",
    "INFER_FITS_ROOT = \"./Data/Inferrence/FITS\"\n",
    "INFER_MASKS_ROOT = \"./Data/Inferrence/Masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "252c7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_fits(f):\n",
    "    hpc_coords = all_coordinates_from_map(f)\n",
    "    mask = coordinate_is_on_solar_disk(hpc_coords)\n",
    "    palette = f.cmap.copy()\n",
    "    palette.set_bad(\"black\")\n",
    "    scaled_map = sunpy.map.Map(f.data, f.meta, mask=~mask)\n",
    "    ff = scaled_map.data\n",
    "    return ff\n",
    "\n",
    "\n",
    "def prepare_fits(path, mask_disk=True, clip_low=1, clip_high=99):\n",
    "    f = sunpy.map.Map(path)\n",
    "    if mask_disk:\n",
    "        ff = mask_fits(f).data\n",
    "    else:\n",
    "        ff = f.data\n",
    "\n",
    "    low = np.percentile(ff, clip_low)\n",
    "    high = np.percentile(ff, clip_high)\n",
    "    ff = np.clip(ff, low, high)\n",
    "    ff = (ff - low) / (high - low + 1e-6)\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33ec3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mask(path):\n",
    "    \"\"\"\n",
    "    Read PNG mask (0/255-ish) and return 0/1 float32 array.\n",
    "\n",
    "    We *don't* rename; we just read your existing _CH_MASK_FINAL.png.\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "\n",
    "    im = Image.open(path).convert(\"L\")\n",
    "    arr = np.array(im, dtype=np.float32)\n",
    "    # Consider >127 as CH\n",
    "    arr = (arr > 127).astype(np.float32)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b4f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "\n",
    "def prepare_dataset(fits_root, masks_root):\n",
    "    def index(p):\n",
    "        return p.split(\"/\")[-1][3:16]\n",
    "\n",
    "    # Collect all FITS and masks\n",
    "    fits_files = glob.glob(os.path.join(fits_root, \"**\", \"*.fits\"), recursive=True)\n",
    "    mask_files = glob.glob(\n",
    "        os.path.join(masks_root, \"**\", \"*_CH_MASK_FINAL.png\"), recursive=True\n",
    "    )\n",
    "\n",
    "    df_fits = pd.DataFrame(\n",
    "        {\n",
    "            \"key\": [index(p) for p in fits_files],\n",
    "            \"fits_path\": fits_files,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_masks = pd.DataFrame(\n",
    "        {\n",
    "            \"key\": [index(p) for p in mask_files],\n",
    "            \"mask_path\": mask_files,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Optional: detect duplicate keys (same timestamp, multiple files)\n",
    "    dup_fits = df_fits[df_fits.duplicated(\"key\", keep=False)]\n",
    "    dup_masks = df_masks[df_masks.duplicated(\"key\", keep=False)]\n",
    "\n",
    "    if not dup_fits.empty:\n",
    "        print(\"⚠ Duplicate keys in FITS:\")\n",
    "        print(dup_fits.sort_values(\"key\"))\n",
    "\n",
    "    if not dup_masks.empty:\n",
    "        print(\"⚠ Duplicate keys in masks:\")\n",
    "        print(dup_masks.sort_values(\"key\"))\n",
    "\n",
    "    df_fits = df_fits.drop_duplicates(\"key\", keep=\"first\")\n",
    "    df_masks = df_masks.drop_duplicates(\"key\", keep=\"first\")\n",
    "\n",
    "    # Outer join to see everything in one table\n",
    "    merged = df_fits.merge(df_masks, on=\"key\", how=\"outer\", indicator=True)\n",
    "\n",
    "    matches = merged[merged[\"_merge\"] == \"both\"].copy()\n",
    "    fits_only = merged[merged[\"_merge\"] == \"left_only\"].copy()\n",
    "    masks_only = merged[merged[\"_merge\"] == \"right_only\"].copy()\n",
    "\n",
    "    for df in (matches, fits_only, masks_only):\n",
    "        df.drop(columns=[\"_merge\"], inplace=True)\n",
    "\n",
    "    matches.set_index(matches.key, inplace=True, drop=True)\n",
    "    matches.drop([\"key\"], axis=1, inplace=True)\n",
    "\n",
    "    return matches, fits_only, masks_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1a6e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Duplicate keys in FITS:\n",
      "                key                                          fits_path\n",
      "9182  20170125_2146  ./Data/Inferrence/FITS/2017/01/25/AIA20170125_...\n",
      "9130  20170125_2146  ./Data/Inferrence/FITS/2017/01/25/AIA20170125_...\n",
      "5507  20170712_2154  ./Data/Inferrence/FITS/2017/07/12/AIA20170712_...\n",
      "5596  20170712_2154  ./Data/Inferrence/FITS/2017/07/12/AIA20170712_...\n",
      "7885  20170801_0054  ./Data/Inferrence/FITS/2017/08/01/AIA20170801_...\n",
      "...             ...                                                ...\n",
      "7790  20170831_2154  ./Data/Inferrence/FITS/2017/08/31/AIA20170831_...\n",
      "6787  20170831_2254  ./Data/Inferrence/FITS/2017/09/08/31/AIA201708...\n",
      "7800  20170831_2254  ./Data/Inferrence/FITS/2017/08/31/AIA20170831_...\n",
      "6794  20170831_2354  ./Data/Inferrence/FITS/2017/09/08/31/AIA201708...\n",
      "7807  20170831_2354  ./Data/Inferrence/FITS/2017/08/31/AIA20170831_...\n",
      "\n",
      "[1550 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = prepare_dataset(TRAIN_FITS_ROOT, TRAIN_MASKS_ROOT)[0]\n",
    "inf_df = prepare_dataset(INFER_FITS_ROOT, INFER_MASKS_ROOT)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9bf673",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02ff80",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beb98bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_pair(img, mask):\n",
    "    # --- random horizontal flip ---\n",
    "    if np.random.rand() < 0.5:\n",
    "        img = img[:, ::-1, :]\n",
    "        mask = mask[:, ::-1, :]\n",
    "\n",
    "    # --- small random brightness scaling ---\n",
    "    scale = np.random.uniform(0.9, 1.1)  # ±10 %\n",
    "    img = img * scale\n",
    "    img = np.clip(img, 0.0, 1.0)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16896fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pair(fits_path, mask_path):\n",
    "    # decode paths if coming in as bytes\n",
    "    if isinstance(fits_path, (bytes, np.bytes_)):\n",
    "        fits_path = fits_path.decode(\"utf-8\")\n",
    "    if isinstance(mask_path, (bytes, np.bytes_)):\n",
    "        mask_path = mask_path.decode(\"utf-8\")\n",
    "\n",
    "    # load 2-D arrays\n",
    "    img = np.asarray(prepare_fits(fits_path), dtype=np.float32)\n",
    "    mask = np.asarray(prepare_mask(mask_path), dtype=np.float32)\n",
    "\n",
    "    # resize\n",
    "    img_resized = PIL.Image.fromarray((img * 255).astype(np.uint8)).resize(\n",
    "        (IMG_SIZE, IMG_SIZE), resample=PIL.Image.BILINEAR\n",
    "    )\n",
    "    mask_resized = PIL.Image.fromarray((mask * 255).astype(np.uint8)).resize(\n",
    "        (IMG_SIZE, IMG_SIZE), resample=PIL.Image.NEAREST\n",
    "    )\n",
    "\n",
    "    # normalize back to [0,1] and add channel axis\n",
    "    img = np.expand_dims(np.array(img_resized, dtype=np.float32) / 255.0, axis=-1)\n",
    "    mask = np.expand_dims(np.array(mask_resized, dtype=np.float32) / 255.0, axis=-1)\n",
    "    mask = (mask > 0.5).astype(np.float32)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577ba2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_generator(fits_paths, mask_paths, batch_size, augment=False):\n",
    "    n = len(fits_paths)\n",
    "    idxs = np.arange(n)\n",
    "\n",
    "    while True:\n",
    "        np.random.shuffle(idxs)\n",
    "        for i in range(0, n, batch_size):\n",
    "            batch_idx = idxs[i : i + batch_size]\n",
    "            imgs, masks = [], []\n",
    "            for j in batch_idx:\n",
    "                img, mask = load_pair(fits_paths[j], mask_paths[j])\n",
    "                if augment:\n",
    "                    img, mask = augment_pair(img, mask)\n",
    "\n",
    "                imgs.append(img)\n",
    "                masks.append(mask)\n",
    "\n",
    "            if not imgs:\n",
    "                continue\n",
    "\n",
    "            X = np.stack(imgs, axis=0).astype(np.float32)  # (B, H, W, 1)\n",
    "            Y = np.stack(masks, axis=0).astype(np.float32)  # (B, H, W, 1)\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb330829",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccd340a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(x, filters):\n",
    "    x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e94e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape=(IMG_SIZE, IMG_SIZE, 1), base_filters=32):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # processedinputs = .....(inputs)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = double_conv(inputs, base_filters)\n",
    "    p1 = layers.MaxPool2D(2)(c1)\n",
    "\n",
    "    c2 = double_conv(p1, base_filters * 2)\n",
    "    p2 = layers.MaxPool2D(2)(c2)\n",
    "\n",
    "    c3 = double_conv(p2, base_filters * 4)\n",
    "    p3 = layers.MaxPool2D(2)(c3)\n",
    "\n",
    "    c4 = double_conv(p3, base_filters * 8)\n",
    "    p4 = layers.MaxPool2D(2)(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    bn = double_conv(p4, base_filters * 16)\n",
    "\n",
    "    # Decoder\n",
    "    u4 = layers.Conv2DTranspose(base_filters * 8, 2, strides=2, padding=\"same\")(bn)\n",
    "    u4 = layers.Concatenate()([u4, c4])\n",
    "    c5 = double_conv(u4, base_filters * 8)\n",
    "\n",
    "    u3 = layers.Conv2DTranspose(base_filters * 4, 2, strides=2, padding=\"same\")(c5)\n",
    "    u3 = layers.Concatenate()([u3, c3])\n",
    "    c6 = double_conv(u3, base_filters * 4)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(base_filters * 2, 2, strides=2, padding=\"same\")(c6)\n",
    "    u2 = layers.Concatenate()([u2, c2])\n",
    "    c7 = double_conv(u2, base_filters * 2)\n",
    "\n",
    "    u1 = layers.Conv2DTranspose(base_filters, 2, strides=2, padding=\"same\")(c7)\n",
    "    u1 = layers.Concatenate()([u1, c1])\n",
    "    c8 = double_conv(u1, base_filters)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(c8)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"CH_UNet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fc17ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    # flatten per-sample\n",
    "    y_true_f = ops.reshape(y_true, (ops.shape(y_true)[0], -1))\n",
    "    y_pred_f = ops.reshape(y_pred, (ops.shape(y_pred)[0], -1))\n",
    "\n",
    "    intersection = ops.sum(y_true_f * y_pred_f, axis=1)\n",
    "    denom = ops.sum(y_true_f, axis=1) + ops.sum(y_pred_f, axis=1)\n",
    "\n",
    "    dice = (2.0 * intersection + smooth) / (denom + smooth)\n",
    "    return ops.mean(dice)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dice_loss = 1.0 - dice_coef(y_true, y_pred)\n",
    "    return 0.4 * ops.mean(bce) + 0.6 * dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "416ee6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(pairs_df):\n",
    "    fits_paths = pairs_df[\"fits_path\"].astype(str).tolist()\n",
    "    mask_paths = pairs_df[\"mask_path\"].astype(str).tolist()\n",
    "\n",
    "    if len(fits_paths) == 0:\n",
    "        raise RuntimeError(\"pairs_df is empty: no FITS-mask pairs to train on.\")\n",
    "    if len(fits_paths) != len(mask_paths):\n",
    "        raise RuntimeError(\n",
    "            f\"Mismatch in pairs_df: {len(fits_paths)} FITS vs {len(mask_paths)} masks.\"\n",
    "        )\n",
    "\n",
    "    n_total = len(fits_paths)\n",
    "    print(f\"Training on {n_total} FITS-mask pairs\")\n",
    "\n",
    "    # 90/10 split\n",
    "    n_val = max(1, int(0.1 * n_total))\n",
    "    n_train = n_total - n_val\n",
    "\n",
    "    train_fits = fits_paths[:n_train]\n",
    "    train_masks = mask_paths[:n_train]\n",
    "    val_fits = fits_paths[n_train:]\n",
    "    val_masks = mask_paths[n_train:]\n",
    "\n",
    "    # steps per epoch (integer)\n",
    "    steps_per_epoch = max(1, n_train // BATCH_SIZE)\n",
    "    val_steps = max(1, n_val // BATCH_SIZE)\n",
    "\n",
    "    train_gen = pair_generator(\n",
    "        train_fits,\n",
    "        train_masks,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        augment=True,  # set False if you don't want augmentation\n",
    "    )\n",
    "\n",
    "    val_gen = pair_generator(\n",
    "        val_fits,\n",
    "        val_masks,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        augment=False,\n",
    "    )\n",
    "\n",
    "    model = build_unet(base_filters=32)  # must be built with keras.layers, not tf.keras\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=bce_dice_loss,  # your keras.ops-based loss\n",
    "        metrics=[dice_coef, \"accuracy\"],\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            MODEL_PATH,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=val_steps,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    print(f\"Training finished. Best model saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2056220f",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7619f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model():\n",
    "    custom_objects = {\n",
    "        \"bce_dice_loss\": bce_dice_loss,\n",
    "        \"dice_coef\": dice_coef,\n",
    "    }\n",
    "    model = keras.models.load_model(MODEL_PATH, custom_objects=custom_objects)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4652d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6e922ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1763025204.063167 9056719 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1763025204.127443 9056719 service.cc:145] XLA service 0x3141e7770 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1763025204.127467 9056719 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1763025204.131211 9056719 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1763025204.131227 9056719 mps_client.cc:384] XLA backend will use up to 12712722432 bytes on device 0 for SimpleAllocator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.92 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_trained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a0a62",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "909a451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model_to_array(model, img2d, resize=False, img_size=IMG_SIZE):\n",
    "    \"\"\"\n",
    "    img2d : 2D numpy array (H, W), already preprocessed (normalized etc.)\n",
    "    model : trained Keras model (Keras 3, any backend)\n",
    "    resize: if True and shape != (img_size, img_size), resizes with bilinear\n",
    "    img_size: target size for the model input\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prob_map : 2D numpy array (img_size, img_size) with values in [0, 1]\n",
    "    \"\"\"\n",
    "    img = np.asarray(img2d, dtype=np.float32)\n",
    "\n",
    "    if img.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D array, got shape {img.shape}\")\n",
    "\n",
    "    # Optional resize to model input size\n",
    "    if resize and img.shape != (img_size, img_size):\n",
    "        # Use float-preserving PIL mode \"F\", bilinear interpolation\n",
    "        pil_img = PIL.Image.fromarray(img.astype(np.float32), mode=\"F\")\n",
    "        pil_img = pil_img.resize((img_size, img_size), resample=PIL.Image.BILINEAR)\n",
    "        img = np.array(pil_img, dtype=np.float32)\n",
    "\n",
    "    # Add channel and batch dims: (H, W) -> (1, H, W, 1)\n",
    "    x = img[np.newaxis, ..., np.newaxis]  # (1, H, W, 1)\n",
    "\n",
    "    # Predict: output shape (1, H, W, 1) -> (H, W)\n",
    "    prob = model.predict(x, verbose=0)[0, ..., 0]\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcdc42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_via_model(path):\n",
    "    prob_map = apply_model_to_array(model, path, resize=True)\n",
    "    mask = (prob_map > 0.5).astype(np.float32)  # binary mask if you want it\n",
    "    mask_uint8 = (mask * 255).clip(0, 255).astype(np.uint8)\n",
    "    img = PIL.Image.fromarray(mask_uint8, mode=\"L\")\n",
    "\n",
    "    if img.size != (1024, 1024):\n",
    "        img = img.resize((1024, 1024), resample=PIL.Image.NEAREST)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f863417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_map_via_model(path):\n",
    "    prob_map = apply_model_to_array(model, path, resize=True)\n",
    "    img_uint8 = np.clip(prob_map * 255, 0, 255).astype(np.uint8)\n",
    "    img = PIL.Image.fromarray(img_uint8, mode=\"L\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e033410",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = ct.aia_color_table(u.Quantity(193, \"Angstrom\"))\n",
    "# cmap = \"gray\"\n",
    "\n",
    "\n",
    "def plot_mask(row, sdo=False):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.array(mask_via_model(prepare_fits(row.fits_path))), cmap=cmap)\n",
    "    plt.title(\"helio-n\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.array(PIL.Image.open(row.mask_path)), cmap=cmap)\n",
    "    plt.title(\"IDL\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sdo(row):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(prepare_fits(row.fits_path), cmap=cmap)\n",
    "    plt.contour(\n",
    "        np.array(mask_via_model(prepare_fits(row.fits_path))),\n",
    "        levels=[0.5],\n",
    "        colors=\"red\",\n",
    "        linewidths=1.5,\n",
    "    )\n",
    "    plt.title(\"helio-n\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(prepare_fits(row.fits_path), cmap=cmap)\n",
    "    plt.contour(\n",
    "        np.array(prepare_mask(row.mask_path)),\n",
    "        levels=[0.5],\n",
    "        colors=\"red\",\n",
    "        linewidths=1.5,\n",
    "    )\n",
    "    plt.title(\"IDL\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc07cae97bbc4a92b2cfb359830fb074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(RadioButtons(description='DataFrame:', options=('train', 'inferrence'), value='train'), IntSlid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# 1. Register your dataframes here\n",
    "dfs = {\n",
    "    \"train\": train_df,\n",
    "    \"inferrence\": inf_df,\n",
    "}\n",
    "\n",
    "# 2. Widgets\n",
    "df_selector = widgets.RadioButtons(\n",
    "    options=list(dfs.keys()),\n",
    "    value=\"train\",\n",
    "    description=\"DataFrame:\",\n",
    ")\n",
    "\n",
    "idx_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(dfs[\"train\"]) - 1,\n",
    "    step=1,\n",
    "    description=\"Index:\",\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "show_mask_checkbox = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description=\"Show mask (off = SDO)\",\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "# 3. Update slider range when DF changes\n",
    "def update_slider_range(change):\n",
    "    df = dfs[df_selector.value]\n",
    "    idx_slider.max = max(0, len(df) - 1)\n",
    "    if idx_slider.value > idx_slider.max:\n",
    "        idx_slider.value = idx_slider.max\n",
    "\n",
    "\n",
    "df_selector.observe(update_slider_range, names=\"value\")\n",
    "\n",
    "\n",
    "# 4. Main update function\n",
    "def update_plot(change=None):\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        df = dfs[df_selector.value]\n",
    "        if len(df) == 0:\n",
    "            print(\"Selected dataframe is empty.\")\n",
    "            return\n",
    "\n",
    "        row = df.iloc[idx_slider.value]\n",
    "\n",
    "        if show_mask_checkbox.value:\n",
    "            # You implement this: should plot SDO + NN/IDL mask\n",
    "            plot_mask(row)\n",
    "        else:\n",
    "            # You implement this: should plot just the SDO / FITS-based view\n",
    "            plot_sdo(row)\n",
    "\n",
    "\n",
    "# 5. Hook up callbacks\n",
    "idx_slider.observe(update_plot, names=\"value\")\n",
    "show_mask_checkbox.observe(update_plot, names=\"value\")\n",
    "df_selector.observe(update_plot, names=\"value\")\n",
    "\n",
    "# 6. Display the UI\n",
    "ui = widgets.VBox(\n",
    "    [\n",
    "        df_selector,\n",
    "        idx_slider,\n",
    "        show_mask_checkbox,\n",
    "        out,\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(ui)\n",
    "\n",
    "# Initial draw\n",
    "update_slider_range(None)\n",
    "update_plot(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2650f268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89c79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fe61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icme3.10 (TF, Metal)",
   "language": "python",
   "name": "icme3.10-nn-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
