{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import sunpy.map\n",
    "from sunpy.map.maputils import all_coordinates_from_map, coordinate_is_on_solar_disk\n",
    "import pandas as pd\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5786ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 1024\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7af97",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FITS_ROOT = \"./Data/Training/FITS\"\n",
    "TRAIN_MASKS_ROOT = \"./Data/Training/Masks\"\n",
    "\n",
    "MODEL_PATH = \"model_CH_UNet.h5\"\n",
    "\n",
    "INFER_FITS_ROOT = \"./Data/Inferrence/FITS\"\n",
    "INFER_MASKS_ROOT = \"./Data/Inferrence/Masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_fits(f):\n",
    "    hpc_coords = all_coordinates_from_map(f)\n",
    "    mask = coordinate_is_on_solar_disk(hpc_coords)\n",
    "    palette = f.cmap.copy()\n",
    "    palette.set_bad(\"black\")\n",
    "    scaled_map = sunpy.map.Map(f.data, f.meta, mask=~mask)\n",
    "    ff = scaled_map.data\n",
    "    return ff\n",
    "\n",
    "def prepare_fits(path, mask_disk=True, clip_low=1, clip_high=99):\n",
    "    f = sunpy.map.Map(path)\n",
    "    if mask_disk:\n",
    "        ff = mask_fits(f).data\n",
    "    else:\n",
    "        ff = f.data\n",
    "\n",
    "    low = np.percentile(ff, clip_low)\n",
    "    high = np.percentile(ff, clip_high)\n",
    "    ff = np.clip(ff, low, high)\n",
    "    ff = (ff - low) / (high - low + 1e-6)\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mask(path):\n",
    "    \"\"\"\n",
    "    Read PNG mask (0/255-ish) and return 0/1 float32 array.\n",
    "\n",
    "    We *don't* rename; we just read your existing _CH_MASK_FINAL.png.\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "\n",
    "    im = Image.open(path).convert(\"L\")\n",
    "    arr = np.array(im, dtype=np.float32)\n",
    "    # Consider >127 as CH\n",
    "    arr = (arr > 127).astype(np.float32)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(fits_root, masks_root):\n",
    "    def index(p):\n",
    "        return p.split(\"/\")[-1][3:16]\n",
    "\n",
    "    fits_re = re.compile(r\"AIA(\\d{8})_\\d{4,6}_(\\d{4})\\.fits$\")\n",
    "    mask_re = re.compile(r\"AIA(\\d{8})_\\d{6}_(\\d{4})_CH_MASK_FINAL\\.png$\")\n",
    "\n",
    "    # Collect all FITS and masks\n",
    "    fits_files = glob.glob(os.path.join(fits_root, \"**\", \"*.fits\"), recursive=True)\n",
    "    mask_files = glob.glob(\n",
    "        os.path.join(masks_root, \"**\", \"*_CH_MASK_FINAL.png\"), recursive=True\n",
    "    )\n",
    "\n",
    "    df_fits = pd.DataFrame(\n",
    "    {\n",
    "        \"key\": [index(p) for p in fits_files],\n",
    "        \"fits_path\": fits_files,\n",
    "    }\n",
    "    )\n",
    "\n",
    "    df_masks = pd.DataFrame(\n",
    "        {\n",
    "            \"key\": [index(p) for p in mask_files],\n",
    "            \"mask_path\": mask_files,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Optional: detect duplicate keys (same timestamp, multiple files)\n",
    "    dup_fits = df_fits[df_fits.duplicated(\"key\", keep=False)]\n",
    "    dup_masks = df_masks[df_masks.duplicated(\"key\", keep=False)]\n",
    "\n",
    "    if not dup_fits.empty:\n",
    "        print(\"⚠ Duplicate keys in FITS:\")\n",
    "        print(dup_fits.sort_values(\"key\"))\n",
    "\n",
    "    if not dup_masks.empty:\n",
    "        print(\"⚠ Duplicate keys in masks:\")\n",
    "        print(dup_masks.sort_values(\"key\"))\n",
    "\n",
    "    # Outer join to see everything in one table\n",
    "    merged = df_fits.merge(df_masks, on=\"key\", how=\"outer\", indicator=True)\n",
    "\n",
    "    matches = merged[merged[\"_merge\"] == \"both\"].copy()\n",
    "    fits_only = merged[merged[\"_merge\"] == \"left_only\"].copy()\n",
    "    masks_only = merged[merged[\"_merge\"] == \"right_only\"].copy()\n",
    "\n",
    "\n",
    "    for df in (matches, fits_only, masks_only):\n",
    "        df.drop(columns=[\"_merge\"], inplace=True)\n",
    "\n",
    "    matches.set_index(matches.key, inplace=True, drop=True)\n",
    "    matches.drop([\"key\"], axis=1, inplace=True)\n",
    "\n",
    "    return matches, fits_only, masks_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prepare_dataset(TRAIN_FITS_ROOT, TRAIN_MASKS_ROOT)[0]\n",
    "inf_df = prepare_dataset(INFER_FITS_ROOT, INFER_MASKS_ROOT)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9bf673",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb98bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_pair(img, mask):\n",
    "    # --- random horizontal flip ---\n",
    "    stacked = tf.concat([img, mask], axis=-1)          # (H, W, 2)\n",
    "    stacked = tf.cond(\n",
    "        tf.random.uniform(()) > 0.5,\n",
    "        lambda: tf.image.flip_left_right(stacked),\n",
    "        lambda: stacked,\n",
    "    )\n",
    "    img, mask = stacked[..., :1], stacked[..., 1:]\n",
    "    \n",
    "    # --- small random brightness scaling ---\n",
    "    \n",
    "    scale = tf.random.uniform((), 0.9, 1.1)            # ±10 %\n",
    "    img = img * scale\n",
    "    img = tf.clip_by_value(img, 0.0, 1.0)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16896fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_pair_numpy(fits_path, mask_path):\n",
    "    # fits_path, mask_path come from tf.numpy_function as bytes or strings\n",
    "    fits_path = fits_path.decode(\"utf-8\") if isinstance(fits_path, (bytes, np.bytes_)) else fits_path\n",
    "    mask_path = mask_path.decode(\"utf-8\") if isinstance(mask_path, (bytes, np.bytes_)) else mask_path\n",
    "\n",
    "    img  = prepare_fits(fits_path)   # 2D np array\n",
    "    mask = prepare_mask(mask_path)   # 2D np array\n",
    "\n",
    "    img  = np.asarray(img, dtype=np.float32)\n",
    "    mask = np.asarray(mask, dtype=np.float32)\n",
    "\n",
    "    if img.ndim == 2:\n",
    "        img = img[..., np.newaxis]\n",
    "    if mask.ndim == 2:\n",
    "        mask = mask[..., np.newaxis]\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "def load_pair_tf(fits_path, mask_path):\n",
    "    img, mask = tf.numpy_function(\n",
    "        _load_pair_numpy,\n",
    "        [fits_path, mask_path],\n",
    "        [tf.float32, tf.float32],\n",
    "    )\n",
    "\n",
    "    img.set_shape((IMG_SIZE, IMG_SIZE, 1))\n",
    "    mask.set_shape((IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "    img, mask = augment_pair(img, mask)\n",
    "\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd340a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(x, filters):\n",
    "    x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e94e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape=(IMG_SIZE, IMG_SIZE, 1), base_filters=32):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = double_conv(inputs, base_filters)\n",
    "    p1 = layers.MaxPool2D(2)(c1)\n",
    "\n",
    "    c2 = double_conv(p1, base_filters * 2)\n",
    "    p2 = layers.MaxPool2D(2)(c2)\n",
    "\n",
    "    c3 = double_conv(p2, base_filters * 4)\n",
    "    p3 = layers.MaxPool2D(2)(c3)\n",
    "\n",
    "    c4 = double_conv(p3, base_filters * 8)\n",
    "    p4 = layers.MaxPool2D(2)(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    bn = double_conv(p4, base_filters * 16)\n",
    "\n",
    "    # Decoder\n",
    "    u4 = layers.Conv2DTranspose(base_filters * 8, 2, strides=2, padding=\"same\")(bn)\n",
    "    u4 = layers.Concatenate()([u4, c4])\n",
    "    c5 = double_conv(u4, base_filters * 8)\n",
    "\n",
    "    u3 = layers.Conv2DTranspose(base_filters * 4, 2, strides=2, padding=\"same\")(c5)\n",
    "    u3 = layers.Concatenate()([u3, c3])\n",
    "    c6 = double_conv(u3, base_filters * 4)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(base_filters * 2, 2, strides=2, padding=\"same\")(c6)\n",
    "    u2 = layers.Concatenate()([u2, c2])\n",
    "    c7 = double_conv(u2, base_filters * 2)\n",
    "\n",
    "    u1 = layers.Conv2DTranspose(base_filters, 2, strides=2, padding=\"same\")(c7)\n",
    "    u1 = layers.Concatenate()([u1, c1])\n",
    "    c8 = double_conv(u1, base_filters)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(c8)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"CH_UNet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36af02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_tiny_unet(input_shape=(IMG_SIZE, IMG_SIZE, 1), base_filters=16):\n",
    "    \"\"\"\n",
    "    Smaller, dumber U-Net:\n",
    "      - Only 3 downsampling levels\n",
    "      - Much fewer filters\n",
    "      - Cheaper to train, less capacity\n",
    "\n",
    "    Suitable when you care more about speed than squeezing out last % IoU.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder (3 levels instead of 4–5)\n",
    "    c1 = double_conv(inputs, base_filters)          #  H x  W\n",
    "    p1 = layers.MaxPool2D(2)(c1)                   # H/2 x W/2\n",
    "\n",
    "    c2 = double_conv(p1, base_filters * 2)          # H/2 x W/2\n",
    "    p2 = layers.MaxPool2D(2)(c2)                   # H/4 x W/4\n",
    "\n",
    "    c3 = double_conv(p2, base_filters * 4)          # H/4 x W/4\n",
    "    p3 = layers.MaxPool2D(2)(c3)                   # H/8 x W/8\n",
    "\n",
    "    # Bottleneck\n",
    "    bn = double_conv(p3, base_filters * 8)\n",
    "\n",
    "    # Decoder\n",
    "    u3 = layers.Conv2DTranspose(base_filters * 4, 2, strides=2, padding=\"same\")(bn)\n",
    "    u3 = layers.Concatenate()([u3, c3])\n",
    "    c4 = double_conv(u3, base_filters * 4)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(base_filters * 2, 2, strides=2, padding=\"same\")(c4)\n",
    "    u2 = layers.Concatenate()([u2, c2])\n",
    "    c5 = double_conv(u2, base_filters * 2)\n",
    "\n",
    "    u1 = layers.Conv2DTranspose(base_filters, 2, strides=2, padding=\"same\")(c5)\n",
    "    u1 = layers.Concatenate()([u1, c1])\n",
    "    c6 = double_conv(u1, base_filters)\n",
    "\n",
    "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(c6)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name=\"CH_TinyUNet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc17ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    y_true_f = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
    "    y_pred_f = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=1)\n",
    "    denom = tf.reduce_sum(y_true_f, axis=1) + tf.reduce_sum(y_pred_f, axis=1)\n",
    "\n",
    "    dice = (2.0 * intersection + smooth) / (denom + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce = keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    return 0.4 * tf.reduce_mean(bce) + 0.6 * (1.0 - dice_coef(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2056220f",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7619f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model():\n",
    "    custom_objects = {\n",
    "        \"bce_dice_loss\": bce_dice_loss,\n",
    "        \"dice_coef\": dice_coef,\n",
    "    }\n",
    "    model = keras.models.load_model(MODEL_PATH, custom_objects=custom_objects)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(pairs_df):\n",
    "    \"\"\"\n",
    "    Train U-Net using a DataFrame with columns:\n",
    "      - 'fits_path' : paths to AIA FITS files\n",
    "      - 'mask_path' : paths to corresponding CH_MASK_FINAL images\n",
    "\n",
    "    The DataFrame index (your key) is not used here,\n",
    "    it's just along for the ride.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Extract aligned lists from the DataFrame ---\n",
    "    fits_paths = pairs_df[\"fits_path\"].astype(str).tolist()\n",
    "    mask_paths = pairs_df[\"mask_path\"].astype(str).tolist()\n",
    "\n",
    "    if len(fits_paths) == 0:\n",
    "        raise RuntimeError(\"pairs_df is empty: no FITS-mask pairs to train on.\")\n",
    "\n",
    "    if len(fits_paths) != len(mask_paths):\n",
    "        raise RuntimeError(\n",
    "            f\"Mismatch in pairs_df: {len(fits_paths)} FITS vs {len(mask_paths)} masks.\"\n",
    "        )\n",
    "\n",
    "    n_total = len(fits_paths)\n",
    "    print(f\"Training on {n_total} FITS-mask pairs\")\n",
    "\n",
    "    # --- Build tf.data datasets from the lists ---\n",
    "    fits_paths_tf = tf.constant(fits_paths)\n",
    "    mask_paths_tf = tf.constant(mask_paths)\n",
    "\n",
    "    # Simple temporal-ish split: first 90% train, last 10% val\n",
    "    n_val = max(1, int(0.1 * n_total))\n",
    "    n_train = n_total - n_val\n",
    "\n",
    "    train_fits = fits_paths_tf[:n_train]\n",
    "    train_masks = mask_paths_tf[:n_train]\n",
    "    val_fits = fits_paths_tf[n_train:]\n",
    "    val_masks = mask_paths_tf[n_train:]\n",
    "\n",
    "    train_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices((train_fits, train_masks))\n",
    "        .shuffle(buffer_size=n_train)\n",
    "        .map(load_pair_tf, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    val_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices((val_fits, val_masks))\n",
    "        .map(load_pair_tf, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    # --- Build and compile model ---\n",
    "    model = build_unet(base_filters=32)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=bce_dice_loss,\n",
    "        metrics=[dice_coef, \"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # --- Callbacks for checkpointing & LR scheduling ---\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            MODEL_PATH,\n",
    "            monitor=\"val_loss\",\n",
    "            save_best_only=True, \n",
    "            save_weights_only=False,\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # --- Train ---\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    print(f\"Training finished. Best model saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e922ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a0a62",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model_to_array(model, img2d, resize=False):\n",
    "    \"\"\"\n",
    "    img2d: 2D numpy array (H, W), already preprocessed (normalized, disk masked, etc.)\n",
    "    model: your trained Keras model\n",
    "\n",
    "    Returns:\n",
    "        prob_map: 2D numpy array (img_size, img_size) with values in [0, 1]\n",
    "    \"\"\"\n",
    "    img = np.asarray(img2d, dtype=np.float32)\n",
    "\n",
    "    if img.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D array, got shape {img.shape}\")\n",
    "\n",
    "    # Optional: resize if shape doesn't match training size\n",
    "    if resize and img.shape != (IMG_SIZE, IMG_SIZE):\n",
    "        import tensorflow as tf\n",
    "        img_tf = tf.convert_to_tensor(img[..., np.newaxis])  # (H, W, 1)\n",
    "        img_tf = tf.image.resize(img_tf, (IMG_SIZE, IMG_SIZE), method=\"bilinear\")\n",
    "        img = img_tf.numpy()[..., 0]\n",
    "\n",
    "    # Add channel and batch dims: (H, W) → (1, H, W, 1)\n",
    "    x = img[np.newaxis, ..., np.newaxis]  # (1, H, W, 1)\n",
    "\n",
    "    # Predict\n",
    "    prob = model.predict(x, verbose=0)[0, ..., 0]  # back to (H, W)\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_via_model(path):\n",
    "    prob_map = apply_model_to_array(model, path, resize=True)\n",
    "    mask = (prob_map > 0.5).astype(np.float32)  # binary mask if you want it\n",
    "    mask_uint8 = (mask * 255).clip(0, 255).astype(np.uint8)\n",
    "    img = PIL.Image.fromarray(mask_uint8, mode=\"L\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_via_model(prepare_fits(train_df.iloc[666].fits_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(train_df.iloc[666].mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f73845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icme3.10 (TF, Metal)",
   "language": "python",
   "name": "icme3.10-nn-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
